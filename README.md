ETL: ExtracciÃ³n, TransformaciÃ³n y Carga de Datos en SQL

ğŸ“š DescripciÃ³n del Proyecto

Este proyecto implementa un proceso ETL (Extract, Transform, Load) para la extracciÃ³n, limpieza, transformaciÃ³n y carga de datos en una base de datos SQL, facilitando su acceso y consulta para futuros anÃ¡lisis. El objetivo es estructurar los datos de manera eficiente para mejorar la toma de decisiones y optimizar el rendimiento de consultas.

âš™ï¸ TecnologÃ­as Utilizadas

Python: Pandas, NumPy, Seaborn, Matplotlib

Machine Learning: Scikit-learn (SimpleImputer, IterativeImputer, KNNImputer)

Bases de Datos: MySQL

Conectividad: MySQL Connector

ğŸ”„ Flujo del Proceso ETL

1. ExtracciÃ³n (Extract)

Se obtienen datos desde:

Archivos CSV

Se utilizan conectores como Pandas, MySQL Connector para acceder a la informaciÃ³n.

2. TransformaciÃ³n y Limpieza (Transform)

Una vez extraÃ­dos los datos, se aplican los siguientes procesos:

GestÃ³n de valores nulos: ImputaciÃ³n usando SimpleImputer, IterativeImputer, KNNImputer.

NormalizaciÃ³n y estandarizaciÃ³n: Ajuste de formatos y unidades.

ConversiÃ³n de tipos de datos: Garantiza compatibilidad con SQL.

CodificaciÃ³n de variables categÃ³ricas.

VisualizaciÃ³n y anÃ¡lisis exploratorio con Seaborn y Matplotlib.

3. Carga en Base de Datos (Load)

Los datos procesados se almacenan en una base de datos MySQL, asegurando:

Estructura optimizada mediante esquemas relacionales.

CreaciÃ³n de Ã­ndices y claves forÃ¡neas para mejorar el rendimiento.

Carga incremental o completa usando scripts de automatizaciÃ³n.

ğŸ“Š VisualizaciÃ³n de Datos

Para validar la calidad de los datos y el impacto de las transformaciones, se generan:

GrÃ¡ficos de distribuciÃ³n de datos.

Matrices de correlaciÃ³n entre variables.

Reportes de calidad de datos.

ğŸš€ Futuras Mejoras

âœ¨ ImplementaciÃ³n de pipelines con Apache Airflow.

âœ¨ OptimizaciÃ³n del almacenamiento mediante particionamiento.

âœ¨ IntegraciÃ³n con herramientas como Power BI o Tableau.

âœ¨ ImplementaciÃ³n de un sistema de monitoreo de calidad de datos.


ğŸ”— InstalaciÃ³n y Uso

Requisitos

Python 3.x

MySQL

LibrerÃ­as: Pandas, NumPy, Seaborn, Matplotlib, Scikit-learn, MySQL Connector

InstalaciÃ³n

Clona el repositorio y ejecuta:

pip install -r requirements.txt

EjecuciÃ³n del Proceso ETL

Ejecuta el script principal para iniciar el proceso ETL:

python etl.py

ğŸ“‚ Estructura del Repositorio

/
â”œâ”€â”€ data/               # Archivos de datos 
â”œâ”€â”€ etl.py              # Limpieza y transformaciÃ³n y Carga en base de datos SQL                
â”œâ”€â”€ README.md           # DocumentaciÃ³n

ğŸ¬ Autor

Jacqueline Yusty Espinosa - www.linkedin.com/in/jacquelineyusti
